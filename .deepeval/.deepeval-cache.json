{"test_cases_lookup_map": {"{\"actual_output\": \"Delivered\", \"context\": null, \"expected_output\": \"The shipment is currently in transit\", \"hyperparameters\": null, \"input\": \"What's the status of shipment 1234?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "Correctness (GEval)", "threshold": 0.5, "success": false, "score": 0.045473138506357716, "reason": "The actual output contradicts the expected output by stating the shipment is delivered, while the expected output indicates it is in transit.", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is factually correct based on the expected output. \n \nEvaluation Steps:\n[\n    \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n    \"You should also heavily penalize omission of detail\",\n    \"Vague language, or contradicting OPINIONS, are OK\"\n] \n \nRubric:\nNone"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "gpt-4o", "strict_mode": false, "criteria": "Determine whether the actual output is factually correct based on the expected output.", "include_reason": false, "evaluation_steps": ["Check whether the facts in 'actual output' contradicts any facts in 'expected output'", "You should also heavily penalize omission of detail", "Vague language, or contradicting OPINIONS, are OK"], "evaluation_params": ["input", "actual_output", "expected_output"]}}]}}}